# Efficient Transformer-based Hyper-parameter Optimization for Resource-constrained IoT Environments

Tentative code: 
This code provides the implementations of Transformer-based Reinforcement Learning Hyper-parameter Optimization (TRL-HPO), which is the convergence of transformers and 
Actor-critic Reinforcement Learning. All the code documentation and variable definition mirrors the content of the manuscript published in **IEEE Internet of Things Magazine**. 

The link to the paper (_arxiv_): https://arxiv.org/abs/2403.12237
The link to the paper (_ieee_): https://ieeexplore.ieee.org/document/10570354/

The functional scripts are as follows:
1. Run `run.py` to train the model.
2. Run `analyze_results.py` to evaluate the trained model.
3. Run `explainability_results.py` to evaluate the trained model.
4. Run `flops_count.py` to output the FLOPS of the model.

# Requirements
The requirements are included in the `requirements.txt` file. To install the packages included in this file, use the following command: `pip install -r requirements.txt`


# Citation
@ARTICLE{10570354,
  author={Shaer, Ibrahim and Nikan, Soodeh and Shami, Abdallah},
  journal={IEEE Internet of Things Magazine}, 
  title={Efficient Transformer-Based Hyper-Parameter Optimization for Resource-Constrained IoT Environments}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  keywords={Transformers;Computational modeling;Computer architecture;Convolutional neural networks;Internet of Things;Training;Accuracy},
  doi={10.1109/IOTM.001.2300285}}



# Contact-Info

Please feel free to contact me for any questions or research opportunities. 
- Email: shaeribrahim@gmail.com
- GitHub: https://github.com/ibrahimshaer and https://github.com/Western-OC2-Lab
- LinkedIn: [Ibrahim Shaer](https://www.linkedin.com/in/ibrahim-shaer-714781124/)
- Google Scholar: [Ibrahim Shaer](https://scholar.google.com/citations?user=78fAJ_IAAAAJ&hl=en) and [OC2 Lab](https://scholar.google.com/citations?user=ICvnj9EAAAAJ&hl=en)
